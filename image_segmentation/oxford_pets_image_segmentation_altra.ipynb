{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Image segmentation with a U-Net-like architecture\n",
    "\n",
    "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
    "**Date created:** 2019/03/20<br>\n",
    "**Last modified:** 2020/04/20<br>\n",
    "**Description:** Image segmentation model trained from scratch on the Oxford Pets dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#!curl -O https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
    "#!curl -O https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
    "#!tar -xf images.tar.gz\n",
    "#!tar -xf annotations.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Prepare paths of input images and target segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 7390\n",
      "images/Abyssinian_1.jpg | annotations/trimaps/Abyssinian_1.png\n",
      "images/Abyssinian_10.jpg | annotations/trimaps/Abyssinian_10.png\n",
      "images/Abyssinian_100.jpg | annotations/trimaps/Abyssinian_100.png\n",
      "images/Abyssinian_101.jpg | annotations/trimaps/Abyssinian_101.png\n",
      "images/Abyssinian_102.jpg | annotations/trimaps/Abyssinian_102.png\n",
      "images/Abyssinian_103.jpg | annotations/trimaps/Abyssinian_103.png\n",
      "images/Abyssinian_104.jpg | annotations/trimaps/Abyssinian_104.png\n",
      "images/Abyssinian_105.jpg | annotations/trimaps/Abyssinian_105.png\n",
      "images/Abyssinian_106.jpg | annotations/trimaps/Abyssinian_106.png\n",
      "images/Abyssinian_107.jpg | annotations/trimaps/Abyssinian_107.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_dir = \"images/\"\n",
    "target_dir = \"annotations/trimaps/\"\n",
    "img_size = (160, 160)\n",
    "num_classes = 3\n",
    "batch_size = 80\n",
    "\n",
    "input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "        if fname.endswith(\".jpg\")\n",
    "    ]\n",
    ")\n",
    "target_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(target_dir, fname)\n",
    "        for fname in os.listdir(target_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of samples:\", len(input_img_paths))\n",
    "\n",
    "for input_path, target_path in zip(input_img_paths[:10], target_img_paths[:10]):\n",
    "    print(input_path, \"|\", target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Prepare `Sequence` class to load & vectorize batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, Markdown\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import PIL\n",
    "from PIL import ImageOps\n",
    "\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import tensorflow as tf\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "num_threads = 64\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=num_threads,  inter_op_parallelism_threads=1)\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)\n",
    "\n",
    "class OxfordPets(keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = target_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size)\n",
    "            x[j] = img\n",
    "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            y[j] = np.expand_dims(img, 2)\n",
    "            # Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:\n",
    "            y[j] -= 1\n",
    "        return x, y\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "# Split our img paths into a training and a validation set\n",
    "val_samples = 3200\n",
    "#random.Random(1337).shuffle(input_img_paths)\n",
    "#random.Random(1337).shuffle(target_img_paths)\n",
    "val_input_img_paths = input_img_paths[-val_samples:]\n",
    "val_target_img_paths = target_img_paths[-val_samples:]\n",
    "\n",
    "# Instantiate data Sequences for each split\n",
    "val_gen = OxfordPets(batch_size, img_size, val_input_img_paths, val_target_img_paths)\n",
    "\n",
    "## Load pre-trained model\n",
    "\n",
    "model = keras.models.load_model('oxford_segmentation.h5')\n",
    "\n",
    "## Visualize predictions\n",
    "\n",
    "# Generate predictions for all images in the validation set\n",
    "import time\n",
    "\n",
    "val_gen = OxfordPets(batch_size, img_size, val_input_img_paths, val_target_img_paths)\n",
    "tf_model = tf.function(model)\n",
    "\n",
    "t1 = time.time()\n",
    "val_preds = model.predict(val_gen)\n",
    "t2 = time.time()\n",
    "\n",
    "printmd(\"<span style='font-size:18.0pt'> Image Segmentation Batch Processing Throughput </span>\")\n",
    "printmd(\"<span style='font-size:18.0pt'> Ampere Altra 1P ({} vCPU) </span>\".format(num_threads))\n",
    "\n",
    "printmd(\"<span style='font-size:15.0pt'> Total number of Images {} </span>\".format(len(val_input_img_paths)))\n",
    "printmd(\"<span style='font-size:15.0pt'> Throughput {} FPS </span>\".format(1000 / (t2 - t1)))\n",
    "print(\"Processig time {} ms\".format((t2 - t1) * 1000))\n",
    "\n",
    "\n",
    "def get_mask_image(i):\n",
    "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
    "    mask = np.argmax(val_preds[i], axis=-1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
    "    return img\n",
    "\n",
    "# Display the first 10 input images\n",
    "for i in range(0, 10):\n",
    "  orig_img = Image(filename=val_input_img_paths[i])\n",
    "  mask_img = get_mask_image(i)\n",
    "  display(orig_img)\n",
    "  display(mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "oxford_pets_image_segmentation",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
