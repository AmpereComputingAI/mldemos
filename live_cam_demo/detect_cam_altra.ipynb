{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5664f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from labels import coco_labels\n",
    "from IPython.display import clear_output, Image, display, HTML, Markdown\n",
    "from threading import Thread\n",
    "\n",
    "if sys.version_info >= (3, 0):\n",
    "    from queue import Queue\n",
    "else:\n",
    "    from Queue import Queue\n",
    "    \n",
    "class VideoStream:\n",
    "    def __init__(self, path, queueSize=16):\n",
    "        self.stream = cv2.VideoCapture(path)\n",
    "        self.stopped = False\n",
    "        self.Q = Queue(maxsize=queueSize)\n",
    "    \n",
    "    def update(self):\n",
    "        while True:\n",
    "            if self.stopped:\n",
    "                return\n",
    "            \n",
    "            if not self.Q.full():\n",
    "                grabbed, frame = self.stream.read()                \n",
    "                if not grabbed:\n",
    "                    continue\n",
    "                self.Q.put(frame)\n",
    "            else:\n",
    "                time.sleep(0.04) # If queue is full wait a little bit before looping\n",
    "        \n",
    "    def start(self):\n",
    "        t = Thread(target=self.update, args=())\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "        return self\n",
    "    \n",
    "    def read(self):\n",
    "        return self.Q.get()\n",
    "    \n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        \n",
    "\n",
    "def draw_outputs(img, outputs, class_names):\n",
    "    boxes, objectness, classes, nums = outputs\n",
    "    #boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    boxes, objectness, classes, nums = np.squeeze(boxes), np.squeeze(objectness), np.squeeze(classes), np.squeeze(nums)\n",
    "    hw = img.shape[0:2]\n",
    "    for i in range(int(nums)):    \n",
    "        if objectness[i] < 0.55:\n",
    "            continue\n",
    "        ymin, xmin = (boxes[i][0:2] * hw).astype(np.int32)\n",
    "        ymax, xmax = (boxes[i][2:4] * hw).astype(np.int32)\n",
    "        x1y1 = xmin, ymin\n",
    "        x2y2 = xmax, ymax\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(\n",
    "            class_names[int(classes[i])], objectness[i]),\n",
    "            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "    return img\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "# URL to be replaced based on the camera source\n",
    "import pafy\n",
    "cam_url = 'https://www.youtube.com/watch?v=1EiC9bvVGnk'\n",
    "#cam_url = 'https://www.youtube.com/watch?v=5_XSYlAfJZM'\n",
    "#cam_url = 'https://www.youtube.com/watch?v=HpdO5Kq3o7Y'\n",
    "video = pafy.new(cam_url)\n",
    "cam_url = video.streams[2].url\n",
    "#cam_url = 'http://admin:cDOna5Os@108.71.88.166:80/video.cgi'\n",
    "\n",
    "if cam_url is None:\n",
    "  print(\"CAM URL is not set.\")\n",
    "  quit()\n",
    "    \n",
    "videoStream = VideoStream(cam_url, False)\n",
    "videoStream.start()\n",
    "    \n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "    \n",
    "num_classes = 90\n",
    "num_threads = 6\n",
    "img_size = 320\n",
    "    \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.allow_soft_placement = True\n",
    "config.intra_op_parallelism_threads = num_threads\n",
    "config.inter_op_parallelism_threads = 1\n",
    "    \n",
    "graph = tf.compat.v1.Graph()\n",
    "with graph.as_default():\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.compat.v1.gfile.GFile('./ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb', 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        graph_def.ParseFromString(serialized_graph)\n",
    "        tf.compat.v1.import_graph_def(graph_def, name=\"\")\n",
    "        sess = tf.compat.v1.Session(config=config, graph=graph)\n",
    "    \n",
    "input_names = [\"image_tensor\"]\n",
    "output_names = [\"detection_classes\", \"detection_boxes\", \"detection_scores\", \"num_detections\"]\n",
    "    \n",
    "# Input tensor is the image\n",
    "image_tensor = graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "# Output tensors are the detection boxes, scores, and classes\n",
    "# Each box represents a part of the image where a particular object was detected\n",
    "detection_boxes = graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "# Each score represents level of confidence for each of the objects.\n",
    "# The score is shown on the result image, together with the class label.\n",
    "detection_scores = graph.get_tensor_by_name('detection_scores:0')\n",
    "detection_classes = graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "# Number of objects detected\n",
    "num_detections = graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "times = []\n",
    "\n",
    "printmd(\"<span style='font-size:18.0pt'> Video Stream Object Detection and Classification Latency </span>\")\n",
    "printmd(\"<span style='font-size:18.0pt'> OCI Ampere A1 Altra ({} vCPU) </span>\".format(num_threads))\n",
    "\n",
    "display_handle = display(None, display_id=True)\n",
    "frames = 0\n",
    "         \n",
    "try:\n",
    "    while True:\n",
    "        img = videoStream.read()\n",
    "        \n",
    "        img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_in = cv2.resize(img_in, (img_size, img_size)).astype(\"float32\") \n",
    "        \n",
    "        img_in = img_in[:img_size, :img_size]\n",
    "        img_in = img_in[np.newaxis, :, :, :]\n",
    "        \n",
    "        t1 = time.time()\n",
    "        (boxes, scores, classes, num) = sess.run(\n",
    "                [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                feed_dict={image_tensor: img_in})\n",
    "        t2 = time.time()\n",
    "        times.append(t2-t1)\n",
    "        times = times[-20:]\n",
    "        img = draw_outputs(img, (boxes, scores, classes, num), coco_labels)\n",
    "\n",
    "        latency = sum(times)/len(times) * 1000\n",
    "        img = cv2.putText(img, \"Latency: {:.2f}ms\".format(latency), (0, 30),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 255, 0), 2)\n",
    "        _, img = cv2.imencode('.jpeg', img)\n",
    "      \n",
    "        display_handle.update(Image(data=img.tobytes()))\n",
    "        frames = frames + 1\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    videoStream.stop()\n",
    "    display_handle.update(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
