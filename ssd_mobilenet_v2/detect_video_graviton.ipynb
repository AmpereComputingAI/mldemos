{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5664f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from labels import coco_labels\n",
    "from IPython.display import clear_output, Image, display, HTML, Markdown\n",
    "\n",
    "def draw_outputs(img, outputs, class_names):\n",
    "    boxes, objectness, classes, nums = outputs\n",
    "    #boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    boxes, objectness, classes, nums = np.squeeze(boxes), np.squeeze(objectness), np.squeeze(classes), np.squeeze(nums)\n",
    "    hw = img.shape[0:2]\n",
    "    for i in range(int(nums)):    \n",
    "        if objectness[i] < 0.55:\n",
    "            continue\n",
    "        ymin, xmin = (boxes[i][0:2] * hw).astype(np.int32)\n",
    "        ymax, xmax = (boxes[i][2:4] * hw).astype(np.int32)\n",
    "        x1y1 = xmin, ymin\n",
    "        x2y2 = xmax, ymax\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(\n",
    "            class_names[int(classes[i])], objectness[i]),\n",
    "            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "    return img\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "    \n",
    "num_classes = 90\n",
    "num_threads = 48\n",
    "img_size = 320\n",
    "    \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.allow_soft_placement = True\n",
    "config.intra_op_parallelism_threads = num_threads\n",
    "config.inter_op_parallelism_threads = 1\n",
    "    \n",
    "graph = tf.compat.v1.Graph()\n",
    "with graph.as_default():\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.compat.v1.gfile.GFile('./ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb', 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        graph_def.ParseFromString(serialized_graph)\n",
    "        tf.compat.v1.import_graph_def(graph_def, name=\"\")\n",
    "        sess = tf.compat.v1.Session(config=config, graph=graph)\n",
    "    \n",
    "input_names = [\"image_tensor\"]\n",
    "output_names = [\"detection_classes\", \"detection_boxes\", \"detection_scores\", \"num_detections\"]\n",
    "    \n",
    "# Input tensor is the image\n",
    "image_tensor = graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "# Output tensors are the detection boxes, scores, and classes\n",
    "# Each box represents a part of the image where a particular object was detected\n",
    "detection_boxes = graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "# Each score represents level of confidence for each of the objects.\n",
    "# The score is shown on the result image, together with the class label.\n",
    "detection_scores = graph.get_tensor_by_name('detection_scores:0')\n",
    "detection_classes = graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "# Number of objects detected\n",
    "num_detections = graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "times = []\n",
    "\n",
    "printmd(\"<span style='font-size:18.0pt'> Video Stream Object Detection and Classification Latency </span>\")\n",
    "printmd(\"<span style='font-size:18.0pt'> AWS m6g ({} vCPU) </span>\".format(num_threads))\n",
    "\n",
    "display_handle = display(None, display_id=True)\n",
    "frames = 0\n",
    "vid = cv2.VideoCapture('input_video.mp4')\n",
    "         \n",
    "try:\n",
    "    while True:\n",
    "        _, img = vid.read()\n",
    "        if img is None:\n",
    "            vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            continue\n",
    "                            \n",
    "        img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_in = cv2.resize(img_in, (img_size, img_size)).astype(\"float32\") \n",
    "        \n",
    "        img_in = img_in[:img_size, :img_size]\n",
    "        img_in = img_in[np.newaxis, :, :, :]\n",
    "        \n",
    "        # Measure the time of just session run. Then average of a window of frames\n",
    "        t1 = time.time()\n",
    "        (boxes, scores, classes, num) = sess.run(\n",
    "                [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                feed_dict={image_tensor: img_in})\n",
    "        t2 = time.time()\n",
    "        times.append(t2-t1)\n",
    "        times = times[-20:]\n",
    "        img = draw_outputs(img, (boxes, scores, classes, num), coco_labels)\n",
    "\n",
    "        latency = sum(times)/len(times) * 1000\n",
    "        img = cv2.putText(img, \"Latency: {:.2f}ms\".format(latency), (0, 30),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 255, 0), 2)\n",
    "        _, img = cv2.imencode('.jpeg', img)\n",
    "      \n",
    "        display_handle.update(Image(data=img.tobytes()))\n",
    "        frames = frames + 1\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    vid.release()\n",
    "    display_handle.update(None)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
